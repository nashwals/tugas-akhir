{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usia                 0\n",
       "jenis_kelamin        0\n",
       "kota_asal            0\n",
       "status_pernikahan    0\n",
       "jumlah_anak          0\n",
       "                    ..\n",
       "PV                   0\n",
       "event_load_genap     0\n",
       "EV                   0\n",
       "skor_total           0\n",
       "risiko_stres         0\n",
       "Length: 63, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/burnout_submissions.csv\", keep_default_na=False)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\n",
    "    'risiko_stres', 'personal_vulnerability_ganjil', 'PV',\n",
    "    'event_load_genap', 'EV', 'skor_total'\n",
    "]\n",
    "\n",
    "X = data.drop(columns=features_to_drop)\n",
    "y = data['risiko_stres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 57\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Features: {len(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in risiko_stres: ['High Stress (High Risk)' 'Low Stress (Lowest Risk)'\n",
      " 'Challenged (Low Risk)']\n",
      "Value counts: \n",
      "risiko_stres\n",
      "High Stress (High Risk)     6\n",
      "Low Stress (Lowest Risk)    4\n",
      "Challenged (Low Risk)       1\n",
      "Name: count, dtype: int64\n",
      "Original unique values in encoded labels: [0 1 2]\n",
      "Adjusted unique values in encoded labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique values in risiko_stres: {y.unique()}\")\n",
    "print(f\"Value counts: \\n{y.value_counts()}\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"Original unique values in encoded labels: {np.unique(y_encoded)}\")\n",
    "if y_encoded.min() != 0:\n",
    "    y_encoded = y_encoded - y_encoded.min()\n",
    "print(f\"Adjusted unique values in encoded labels: {np.unique(y_encoded)}\")\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['usia', 'jumlah_anak', 'usia_anak', 'lama_bekerja', 'waktu_bekerja_seminggu', 'beban_sks', 'mhs_bimbingan', 'work_life_balance', 'gaji_sesuai', '1_tidak_mampu', '2_kewalahan_tanggung_jawab', '3_keadaan_tidak_berpihak', '4_waktu_tidak_cukup', '5_tidak_berjalan_baik', '6_terburu_buru', '7_tidak_ada_jalan_keluar', '8_masalah_menumpuk', '9_ingin_menyerah', '10_memikul_beban_berat']\n",
      "Categorical Features: ['jenis_kelamin', 'kota_asal', 'status_pernikahan', 'tinggal_dengan_siapa', 'tinggal_sendiri', 'tinggal_pasangan', 'tinggal_anak', 'tinggal_ortu', 'tinggal_mertua', 'tinggal_saudara', 'tinggal_teman', 'profesi', 'bidang', 'mode_bekerja', 'jarak', 'jabatan_struktural', 'jabatan_fungsional', 'sertifikasi', 'status_keaktifan', 'kesehatan_fisik', 'fisik_mata', 'fisik_punggung', 'fisik_tensi', 'fisik_lemah', 'fisik_kepala', 'fisik_obesitas', 'fisik_imun', 'fisik_carpal', 'kondisi_mental', 'mental_anxiety', 'mental_burnout', 'mental_depresi', 'mental_distress', 'mental_konsentrasi', 'mental_insomnia', 'mental_iritate', 'mental_lelah', 'mental_stres']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numerical Features: {numerical_features}\")\n",
    "print(f\"Categorical Features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RFC': Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(n_estimators=100, random_state=2024))]),\n",
    "    'SVC': Pipeline(steps=[('preprocessor', preprocessor), ('classifier', SVC(kernel='rbf', C=1.0,))]),   \n",
    "    'GBC': Pipeline(steps=[('preprocessor', preprocessor), ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=2024))]),    \n",
    "    'XGB': Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('classifier', XGBClassifier(objective='multi:softmax',\n",
    "                                                        num_class=4,\n",
    "                                                        use_label_encoder=False, \n",
    "                                                        eval_metric='mlogloss',\n",
    "                                                        n_estimators=100,\n",
    "                                                        random_state=2024))]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {model: {'accuracy': [], 'precision': [], 'recall': [], 'f1' : []} for model in models}\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nashwalaisya/supreme/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/nashwalaisya/supreme/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [08:14:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/nashwalaisya/supreme/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/nashwalaisya/supreme/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/nashwalaisya/supreme/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/nashwalaisya/supreme/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     y_pred = model.predict(X_test)\n\u001b[32m      9\u001b[39m     results[name][\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m].append(accuracy_score(y_test, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/supreme/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/supreme/lib/python3.13/site-packages/sklearn/pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/supreme/lib/python3.13/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/supreme/lib/python3.13/site-packages/xgboost/sklearn.py:1758\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1753\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1755\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1756\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1757\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1758\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1759\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1760\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1761\u001b[39m     )\n\u001b[32m   1763\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X, y_encoded):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        results[name]['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        results[name]['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        results[name]['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        results[name]['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "        # Save the last trained version of each model\n",
    "        trained_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Results:\n",
      "Accuracy:  80.0000%\n",
      "Precision: 75.0000%\n",
      "Recall:    80.0000%\n",
      "F1 Score:  76.6667%\n",
      "\n",
      "SVC Results:\n",
      "Accuracy:  70.0000%\n",
      "Precision: 55.0000%\n",
      "Recall:    70.0000%\n",
      "F1 Score:  60.0000%\n",
      "\n",
      "GBC Results:\n",
      "Accuracy:  83.3333%\n",
      "Precision: 85.0000%\n",
      "Recall:    83.3333%\n",
      "F1 Score:  82.2222%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy:  {np.mean(metrics['accuracy'])*100:.4f}%\")\n",
    "    print(f\"Precision: {np.mean(metrics['precision'])*100:.4f}%\")\n",
    "    print(f\"Recall:    {np.mean(metrics['recall'])*100:.4f}%\")\n",
    "    print(f\"F1 Score:  {np.mean(metrics['f1'])*100:.4f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name, X, y, sample_size=10000):\n",
    "    feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "\n",
    "    if model_name in ['XGB', 'RFC', 'GBC']:\n",
    "        importances = model.named_steps['classifier'].feature_importances_\n",
    "    elif model_name == 'SVC':\n",
    "        # --- Ambil sample data untuk mempercepat ---\n",
    "        if len(X) > sample_size:\n",
    "            X_sample, y_sample = resample(\n",
    "                X, y,\n",
    "                n_samples=sample_size,\n",
    "                stratify=y,\n",
    "                random_state=2024\n",
    "            )\n",
    "        else:\n",
    "            X_sample, y_sample = X, y\n",
    "        perm_importance = permutation_importance(\n",
    "            model, \n",
    "            X_sample, y_sample, \n",
    "            n_repeats=5,          # kurangi dari 10 → 5 biar lebih cepat\n",
    "            random_state=2024, \n",
    "            n_jobs=-1             # pakai semua core CPU\n",
    "        )\n",
    "        importances = perm_importance.importances_mean\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    feature_importance = dict(zip(feature_names, importances))\n",
    "    return dict(sorted(feature_importance.items(), key=lambda item: abs(item[1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Boolean array expected for the condition, not int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/ds/tzk88yl5705g6nytd56kbr100000gn/T/ipykernel_33311/2282891524.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X = data[X]\n\u001b[32m      2\u001b[39m y = data[y]\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;28;01min\u001b[39;00m trained_models.items():\n\u001b[32m      4\u001b[39m     print(f\"\\nFeature Importance for {name} (Hybrid):\")\n",
      "\u001b[32m~/supreme/lib/python3.13/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4096\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_slice(key)\n\u001b[32m   4097\u001b[39m \n\u001b[32m   4098\u001b[39m         \u001b[38;5;66;03m# Do we have a (boolean) DataFrame?\u001b[39;00m\n\u001b[32m   4099\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m4100\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.where(key)\n\u001b[32m   4101\u001b[39m \n\u001b[32m   4102\u001b[39m         \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[32m   4103\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n",
      "\u001b[32m~/supreme/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, cond, other, inplace, axis, level)\u001b[39m\n\u001b[32m  11044\u001b[39m                         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m  11045\u001b[39m                     )\n\u001b[32m  11046\u001b[39m \n\u001b[32m  11047\u001b[39m         other = common.apply_if_callable(other, self)\n\u001b[32m> \u001b[39m\u001b[32m11048\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._where(cond, other, inplace, axis, level)\n",
      "\u001b[32m~/supreme/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, cond, other, inplace, axis, level, warn)\u001b[39m\n\u001b[32m  10732\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m ValueError(msg.format(dtype=cond.dtype))\n\u001b[32m  10733\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m  10734\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m _dt \u001b[38;5;28;01min\u001b[39;00m cond.dtypes:\n\u001b[32m  10735\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_bool_dtype(_dt):\n\u001b[32m> \u001b[39m\u001b[32m10736\u001b[39m                         \u001b[38;5;28;01mraise\u001b[39;00m ValueError(msg.format(dtype=_dt))\n\u001b[32m  10737\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m cond._mgr.any_extension_types:\n\u001b[32m  10738\u001b[39m                     \u001b[38;5;66;03m# GH51574: avoid object ndarray conversion later on\u001b[39;00m\n\u001b[32m  10739\u001b[39m                     cond = cond._constructor(\n",
      "\u001b[31mValueError\u001b[39m: Boolean array expected for the condition, not int64"
     ]
    }
   ],
   "source": [
    "X = data[X]\n",
    "y = data[y]\n",
    "for name, model in trained_models.items():\n",
    "    print(f\"\\nFeature Importance for {name} (Hybrid):\")\n",
    "    importance = get_feature_importance(model, name, X, y)\n",
    "    if importance:\n",
    "        for feature, value in importance.items():\n",
    "            print(f\"{feature}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models saved separately with Hybrid encoding\n"
     ]
    }
   ],
   "source": [
    "encoding_scheme = \"hybrid\"\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    filename = f\"{name}_{encoding_scheme}.pkl\"\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"✅ Models saved separately with Hybrid encoding\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Supreme",
   "language": "python",
   "name": "supreme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
