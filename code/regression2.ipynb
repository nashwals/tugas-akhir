{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library\n",
    "\n",
    "In this section, we import various Python libraries that will help us perform data manipulation, visualization, preprocessing, and build machine learning regression models. Each library serves a specific purpose — from handling data to evaluating and visualizing model performance.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "- **pandas (`pd`)**: Used for data manipulation and analysis. It allows easy handling of structured data such as CSV, Excel, or SQL data.\n",
    "- **numpy (`np`)**: Provides mathematical functions and efficient operations on numerical arrays or matrices.\n",
    "- **matplotlib.pyplot (`plt`)**: A plotting library used to create visualizations like line charts, bar charts, scatter plots, etc.\n",
    "- **seaborn (`sns`)**: Built on top of Matplotlib, Seaborn provides a higher-level interface for making attractive and informative statistical graphics.\n",
    "\n",
    "```python\n",
    "from sklearn... import ...\n",
    "```\n",
    "\n",
    "- **sklearn**: This library is used for machine learning tasks such as classification, regression, clustering, and more. It provides a wide range of tools and algorithms to build and evaluate machine learning models.\n",
    "\n",
    "```python\n",
    "from xgboost import XGBRegressor\n",
    "```\n",
    "\n",
    "- **XGBRegressor**: This is an optimized version of gradient boosting that includes additional features and optimizations. It is known for its high performance and efficiency, especially on larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset\n",
    "\n",
    "In this part of the code, we are reading the dataset that contains the training and testing data for our machine learning model. The dataset is stored in a CSV (Comma-Separated Values) file, which is a common format for storing tabular data. We use the `pd.read_csv()` function from the `pandas` library to read the dataset into a DataFrame, which is a two-dimensional data structure that resembles a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usia</th>\n",
       "      <th>jumlah_anak</th>\n",
       "      <th>usia_anak</th>\n",
       "      <th>lama_bekerja</th>\n",
       "      <th>waktu_bekerja_seminggu</th>\n",
       "      <th>beban_sks</th>\n",
       "      <th>mhs_bimbingan</th>\n",
       "      <th>work_life_balance</th>\n",
       "      <th>gaji_sesuai</th>\n",
       "      <th>1_tidak_mampu</th>\n",
       "      <th>...</th>\n",
       "      <th>4_waktu_tidak_cukup</th>\n",
       "      <th>5_tidak_berjalan_baik</th>\n",
       "      <th>6_terburu_buru</th>\n",
       "      <th>7_tidak_ada_jalan_keluar</th>\n",
       "      <th>8_masalah_menumpuk</th>\n",
       "      <th>9_ingin_menyerah</th>\n",
       "      <th>10_memikul_beban_berat</th>\n",
       "      <th>personal_vulnerability_ganjil</th>\n",
       "      <th>event_load_genap</th>\n",
       "      <th>skor_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.363636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>51.090909</td>\n",
       "      <td>22.538182</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>9.727273</td>\n",
       "      <td>14.636364</td>\n",
       "      <td>24.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.384456</td>\n",
       "      <td>0.873863</td>\n",
       "      <td>2.088932</td>\n",
       "      <td>3.413875</td>\n",
       "      <td>6.992203</td>\n",
       "      <td>9.937572</td>\n",
       "      <td>9.526995</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>1.136182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.401298</td>\n",
       "      <td>0.981650</td>\n",
       "      <td>1.286291</td>\n",
       "      <td>1.272078</td>\n",
       "      <td>1.368476</td>\n",
       "      <td>4.649536</td>\n",
       "      <td>5.749308</td>\n",
       "      <td>9.749592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>29.935000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            usia  jumlah_anak  usia_anak  lama_bekerja  \\\n",
       "count  11.000000    11.000000  11.000000     11.000000   \n",
       "mean   33.363636     0.818182   1.818182      6.363636   \n",
       "std     3.384456     0.873863   2.088932      3.413875   \n",
       "min    26.000000     0.000000   0.000000      0.000000   \n",
       "25%    31.500000     0.000000   0.000000      6.000000   \n",
       "50%    34.000000     1.000000   2.000000      7.000000   \n",
       "75%    35.500000     1.500000   3.000000      8.500000   \n",
       "max    38.000000     2.000000   6.000000     10.000000   \n",
       "\n",
       "       waktu_bekerja_seminggu  beban_sks  mhs_bimbingan  work_life_balance  \\\n",
       "count               11.000000  11.000000      11.000000          11.000000   \n",
       "mean                51.090909  22.538182      11.818182           3.000000   \n",
       "std                  6.992203   9.937572       9.526995           1.095445   \n",
       "min                 40.000000  10.000000       0.000000           2.000000   \n",
       "25%                 45.500000  16.500000       5.000000           2.000000   \n",
       "50%                 50.000000  21.000000       9.000000           3.000000   \n",
       "75%                 58.000000  29.935000      17.000000           4.000000   \n",
       "max                 60.000000  43.000000      30.000000           5.000000   \n",
       "\n",
       "       gaji_sesuai  1_tidak_mampu  ...  4_waktu_tidak_cukup  \\\n",
       "count    11.000000      11.000000  ...            11.000000   \n",
       "mean      3.000000       2.090909  ...             3.272727   \n",
       "std       1.095445       1.136182  ...             1.678744   \n",
       "min       2.000000       1.000000  ...             1.000000   \n",
       "25%       2.000000       1.000000  ...             2.000000   \n",
       "50%       3.000000       2.000000  ...             4.000000   \n",
       "75%       4.000000       2.500000  ...             5.000000   \n",
       "max       5.000000       4.000000  ...             5.000000   \n",
       "\n",
       "       5_tidak_berjalan_baik  6_terburu_buru  7_tidak_ada_jalan_keluar  \\\n",
       "count                   11.0       11.000000                 11.000000   \n",
       "mean                     2.0        3.181818                  1.818182   \n",
       "std                      1.0        1.401298                  0.981650   \n",
       "min                      1.0        1.000000                  1.000000   \n",
       "25%                      1.0        2.500000                  1.000000   \n",
       "50%                      2.0        3.000000                  2.000000   \n",
       "75%                      2.5        4.000000                  2.000000   \n",
       "max                      4.0        5.000000                  4.000000   \n",
       "\n",
       "       8_masalah_menumpuk  9_ingin_menyerah  10_memikul_beban_berat  \\\n",
       "count           11.000000         11.000000               11.000000   \n",
       "mean             2.636364          1.727273                2.545455   \n",
       "std              1.286291          1.272078                1.368476   \n",
       "min              1.000000          1.000000                1.000000   \n",
       "25%              2.000000          1.000000                1.500000   \n",
       "50%              2.000000          1.000000                2.000000   \n",
       "75%              3.500000          2.000000                3.500000   \n",
       "max              5.000000          5.000000                5.000000   \n",
       "\n",
       "       personal_vulnerability_ganjil  event_load_genap  skor_total  \n",
       "count                      11.000000         11.000000   11.000000  \n",
       "mean                        9.727273         14.636364   24.363636  \n",
       "std                         4.649536          5.749308    9.749592  \n",
       "min                         5.000000          5.000000   10.000000  \n",
       "25%                         6.000000         10.000000   16.000000  \n",
       "50%                        11.000000         16.000000   25.000000  \n",
       "75%                        12.000000         19.000000   31.500000  \n",
       "max                        20.000000         22.000000   41.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/burnout_submissions.csv\")\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Features and Target\n",
    "\n",
    "In this part of the code, we define which columns from our dataset will be used as **features (input variables)** and which column will be used as the **target (output variable)** for the regression model.\n",
    "\n",
    "The goal here is to separate the data into two main parts:\n",
    "\n",
    "* **`X` (features):** the variables that will be used by the model to make predictions.\n",
    "* **`y` (target):** the variable that we want the model to predict — in this case, the **total stress score (`skor_total`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\n",
    "    'tinggal_dengan_siapa', 'kesehatan_fisik', 'kondisi_mental',\n",
    "    '1_tidak_mampu', '2_kewalahan_tanggung_jawab', '3_keadaan_tidak_berpihak',\n",
    "    '4_waktu_tidak_cukup', '5_tidak_berjalan_baik', '6_terburu_buru',\n",
    "    '7_tidak_ada_jalan_keluar', '8_masalah_menumpuk', '9_ingin_menyerah',\n",
    "    '10_memikul_beban_berat', 'personal_vulnerability_ganjil', 'PV',\n",
    "    'event_load_genap', 'EV', 'skor_total', 'risiko_stres'\n",
    "]\n",
    "\n",
    "X = data.drop(columns=features_to_drop)\n",
    "y = data['skor_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 44\n",
      "Features: ['usia', 'jenis_kelamin', 'kota_asal', 'status_pernikahan', 'jumlah_anak', 'usia_anak', 'tinggal_sendiri', 'tinggal_pasangan', 'tinggal_anak', 'tinggal_ortu', 'tinggal_mertua', 'tinggal_saudara', 'tinggal_teman', 'profesi', 'bidang', 'lama_bekerja', 'mode_bekerja', 'jarak', 'waktu_bekerja_seminggu', 'beban_sks', 'mhs_bimbingan', 'jabatan_struktural', 'jabatan_fungsional', 'sertifikasi', 'status_keaktifan', 'fisik_mata', 'fisik_punggung', 'fisik_tensi', 'fisik_lemah', 'fisik_kepala', 'fisik_obesitas', 'fisik_imun', 'fisik_carpal', 'mental_anxiety', 'mental_burnout', 'mental_depresi', 'mental_distress', 'mental_konsentrasi', 'mental_insomnia', 'mental_iritate', 'mental_lelah', 'mental_stres', 'work_life_balance', 'gaji_sesuai']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Features: {len(X.columns)}\")\n",
    "print(f\"Features: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Non-Numerical Features\n",
    "\n",
    "Not all features in a dataset are numerical. Some columns may contain **categorical data** (e.g., gender, job position, or living situation) or **boolean values** (e.g., yes/no). Since most machine learning models require numerical input, these categorical variables need to be transformed into numbers.\n",
    "\n",
    "In this part of the code, we identify which features are **numerical** and which are **categorical**, and then apply different preprocessing steps using **`ColumnTransformer`** — scaling numerical data and encoding categorical data.\n",
    "\n",
    "## Step Explanation\n",
    "\n",
    "* **`numerical_features`** → Selects all numeric columns (`int64`, `float64`) to be standardized using `StandardScaler`.\n",
    "* **`categorical_features`** → Selects all non-numeric columns (`object`, `bool`) that require encoding into numbers.\n",
    "* **`ColumnTransformer`** → Combines preprocessing steps for different feature types:\n",
    "\n",
    "  * `'num'`: Applies **`StandardScaler`** to numerical columns so that all values have a mean of 0 and a standard deviation of 1.\n",
    "  * `'cat'`: Applies **`OneHotEncoder`** to categorical columns, converting each category into a binary column (0 or 1).\n",
    "  * `remainder='passthrough'`: Keeps any remaining columns unchanged.\n",
    "\n",
    "## About One-Hot Encoding\n",
    "\n",
    "**One-Hot Encoding** is a method for converting categorical data into a numerical form that machine learning algorithms can interpret. Instead of assigning arbitrary numbers (like 1, 2, 3), which would imply an order or ranking, one-hot encoding creates **binary columns** for each unique category.\n",
    "\n",
    "This ensures that the model treats categories equally without assuming any hierarchy.\n",
    "\n",
    "### One-Hot Encoding Explained\n",
    "\n",
    "Suppose we have a column named `living_status` with three categories: `\"Alone\"`, `\"With Family\"`, and `\"With Friends\"`.\n",
    "\n",
    "Original data:\n",
    "\n",
    "| living_status |\n",
    "| ------------- |\n",
    "| Alone         |\n",
    "| With Family   |\n",
    "| With Friends  |\n",
    "| Alone         |\n",
    "| With Family   |\n",
    "\n",
    "After applying one-hot encoding, it becomes:\n",
    "\n",
    "| living_status_Alone | living_status_WithFamily | living_status_WithFriends |\n",
    "| ------------------- | ------------------------ | ------------------------- |\n",
    "| 1                   | 0                        | 0                         |\n",
    "| 0                   | 1                        | 0                         |\n",
    "| 0                   | 0                        | 1                         |\n",
    "| 1                   | 0                        | 0                         |\n",
    "| 0                   | 1                        | 0                         |\n",
    "\n",
    "## Why This Step Matters\n",
    "\n",
    "* Ensures **all input data is numerical**, which is required for most machine learning algorithms.\n",
    "* Prevents **bias or errors** from arbitrary numeric category encoding.\n",
    "* Makes model training **consistent and reliable**, especially when unseen categories appear in the test set (handled by `handle_unknown='ignore'`).\n",
    "\n",
    "By preprocessing both numerical and categorical features properly, we ensure that the dataset is fully prepared for **model training and evaluation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['usia', 'jumlah_anak', 'usia_anak', 'lama_bekerja', 'waktu_bekerja_seminggu', 'beban_sks', 'mhs_bimbingan', 'work_life_balance', 'gaji_sesuai']\n",
      "Categorical Features: ['jenis_kelamin', 'kota_asal', 'status_pernikahan', 'tinggal_sendiri', 'tinggal_pasangan', 'tinggal_anak', 'tinggal_ortu', 'tinggal_mertua', 'tinggal_saudara', 'tinggal_teman', 'profesi', 'bidang', 'mode_bekerja', 'jarak', 'jabatan_struktural', 'jabatan_fungsional', 'sertifikasi', 'status_keaktifan', 'fisik_mata', 'fisik_punggung', 'fisik_tensi', 'fisik_lemah', 'fisik_kepala', 'fisik_obesitas', 'fisik_imun', 'fisik_carpal', 'mental_anxiety', 'mental_burnout', 'mental_depresi', 'mental_distress', 'mental_konsentrasi', 'mental_insomnia', 'mental_iritate', 'mental_lelah', 'mental_stres']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "print(f\"Numerical Features: {numerical_features}\")\n",
    "print(f\"Categorical Features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah fitur sebelum preprocessing: 44\n",
      "Jumlah fitur setelah preprocessing: 107\n",
      "\n",
      "Bentuk data asli: (11, 44)\n",
      "Bentuk data setelah preprocessing: (11, 107)\n",
      "\n",
      "================================================================================\n",
      "Nama fitur setelah preprocessing:\n",
      "================================================================================\n",
      "  1. num__usia\n",
      "  2. num__jumlah_anak\n",
      "  3. num__usia_anak\n",
      "  4. num__lama_bekerja\n",
      "  5. num__waktu_bekerja_seminggu\n",
      "  6. num__beban_sks\n",
      "  7. num__mhs_bimbingan\n",
      "  8. num__work_life_balance\n",
      "  9. num__gaji_sesuai\n",
      " 10. cat__jenis_kelamin_Laki-laki\n",
      " 11. cat__jenis_kelamin_Perempuan\n",
      " 12. cat__kota_asal_Bandar Lampung\n",
      " 13. cat__kota_asal_Jembrana, Bali\n",
      " 14. cat__kota_asal_Lampung\n",
      " 15. cat__kota_asal_Lampung Selatan\n",
      " 16. cat__kota_asal_Medan\n",
      " 17. cat__kota_asal_Padangsidimpuan\n",
      " 18. cat__kota_asal_Salatiga\n",
      " 19. cat__kota_asal_Semarang\n",
      " 20. cat__kota_asal_Yogyakarta \n",
      " 21. cat__status_pernikahan_Belum Menikah\n",
      " 22. cat__status_pernikahan_Sudah Menikah\n",
      " 23. cat__tinggal_sendiri_False\n",
      " 24. cat__tinggal_sendiri_True\n",
      " 25. cat__tinggal_pasangan_False\n",
      " 26. cat__tinggal_pasangan_True\n",
      " 27. cat__tinggal_anak_False\n",
      " 28. cat__tinggal_anak_True\n",
      " 29. cat__tinggal_ortu_False\n",
      " 30. cat__tinggal_ortu_True\n",
      " 31. cat__tinggal_mertua_False\n",
      " 32. cat__tinggal_mertua_True\n",
      " 33. cat__tinggal_saudara_False\n",
      " 34. cat__tinggal_teman_False\n",
      " 35. cat__tinggal_teman_True\n",
      " 36. cat__profesi_Dosen\n",
      " 37. cat__bidang_Arsitektur\n",
      " 38. cat__bidang_Desain Komunikasi Visual\n",
      " 39. cat__bidang_Fisika\n",
      " 40. cat__bidang_Teknik Biomedik\n",
      " 41. cat__bidang_Teknik Informatika\n",
      " 42. cat__bidang_Teknik Perkeretaapian\n",
      " 43. cat__mode_bekerja_Hybrid\n",
      " 44. cat__mode_bekerja_On-site\n",
      " 45. cat__jarak_1 - 5 km\n",
      " 46. cat__jarak_11 - 15 km\n",
      " 47. cat__jarak_6 - 10 km\n",
      " 48. cat__jarak_< 1 km\n",
      " 49. cat__jabatan_struktural_Jabatan Struktural Lainnya\n",
      " 50. cat__jabatan_struktural_Non Jabatan Struktural\n",
      " 51. cat__jabatan_struktural_Setingkat Dekan dan Kepala UPA / UPT\n",
      " 52. cat__jabatan_struktural_Setingkat Kaprodi dan Ketua KK\n",
      " 53. cat__jabatan_fungsional_Asisten Ahli\n",
      " 54. cat__jabatan_fungsional_Lektor\n",
      " 55. cat__jabatan_fungsional_Non Jabatan Fungsional\n",
      " 56. cat__sertifikasi_Belum Mendapat Sertifikasi\n",
      " 57. cat__sertifikasi_Sudah Tersertifikasi\n",
      " 58. cat__status_keaktifan_Aktif\n",
      " 59. cat__status_keaktifan_Aktif (PDDikti) namun masih melakukan Tugas Belajar\n",
      " 60. cat__fisik_mata_False\n",
      " 61. cat__fisik_mata_True\n",
      " 62. cat__fisik_mata_nan\n",
      " 63. cat__fisik_punggung_False\n",
      " 64. cat__fisik_punggung_True\n",
      " 65. cat__fisik_punggung_nan\n",
      " 66. cat__fisik_tensi_False\n",
      " 67. cat__fisik_tensi_True\n",
      " 68. cat__fisik_tensi_nan\n",
      " 69. cat__fisik_lemah_False\n",
      " 70. cat__fisik_lemah_True\n",
      " 71. cat__fisik_lemah_nan\n",
      " 72. cat__fisik_kepala_False\n",
      " 73. cat__fisik_kepala_True\n",
      " 74. cat__fisik_kepala_nan\n",
      " 75. cat__fisik_obesitas_False\n",
      " 76. cat__fisik_obesitas_True\n",
      " 77. cat__fisik_obesitas_nan\n",
      " 78. cat__fisik_imun_False\n",
      " 79. cat__fisik_imun_True\n",
      " 80. cat__fisik_imun_nan\n",
      " 81. cat__fisik_carpal_False\n",
      " 82. cat__fisik_carpal_True\n",
      " 83. cat__fisik_carpal_nan\n",
      " 84. cat__mental_anxiety_False\n",
      " 85. cat__mental_anxiety_True\n",
      " 86. cat__mental_anxiety_nan\n",
      " 87. cat__mental_burnout_False\n",
      " 88. cat__mental_burnout_True\n",
      " 89. cat__mental_burnout_nan\n",
      " 90. cat__mental_depresi_False\n",
      " 91. cat__mental_depresi_nan\n",
      " 92. cat__mental_distress_False\n",
      " 93. cat__mental_distress_nan\n",
      " 94. cat__mental_konsentrasi_False\n",
      " 95. cat__mental_konsentrasi_True\n",
      " 96. cat__mental_konsentrasi_nan\n",
      " 97. cat__mental_insomnia_False\n",
      " 98. cat__mental_insomnia_True\n",
      " 99. cat__mental_insomnia_nan\n",
      "100. cat__mental_iritate_False\n",
      "101. cat__mental_iritate_nan\n",
      "102. cat__mental_lelah_False\n",
      "103. cat__mental_lelah_True\n",
      "104. cat__mental_lelah_nan\n",
      "105. cat__mental_stres_False\n",
      "106. cat__mental_stres_True\n",
      "107. cat__mental_stres_nan\n",
      "\n",
      "================================================================================\n",
      "5 baris pertama data setelah preprocessing:\n",
      "================================================================================\n",
      "   num__usia  num__jumlah_anak  num__usia_anak  num__lama_bekerja  \\\n",
      "0  -0.422577         -0.981981       -0.912871           0.195503   \n",
      "1   0.507093          1.418416        1.095445           0.502723   \n",
      "2   0.507093          1.418416        2.099603           1.117162   \n",
      "3   0.197203          0.218218        0.091287           0.195503   \n",
      "4  -0.732467         -0.981981       -0.912871          -0.418936   \n",
      "\n",
      "   num__waktu_bekerja_seminggu  num__beban_sks  num__mhs_bimbingan  \\\n",
      "0                    -0.913617       -0.584498            0.900721   \n",
      "1                     1.336336       -0.373419           -0.860689   \n",
      "2                     1.336336        2.159535            1.451161   \n",
      "3                     0.736348       -1.323277           -0.970777   \n",
      "4                    -0.763621        0.773798           -0.310248   \n",
      "\n",
      "   num__work_life_balance  num__gaji_sesuai  cat__jenis_kelamin_Laki-laki  \\\n",
      "0               -0.957427         -0.957427                           1.0   \n",
      "1                0.000000          0.957427                           1.0   \n",
      "2               -0.957427         -0.957427                           1.0   \n",
      "3               -0.957427         -0.957427                           1.0   \n",
      "4               -0.957427         -0.957427                           0.0   \n",
      "\n",
      "   ...  cat__mental_insomnia_True  cat__mental_insomnia_nan  \\\n",
      "0  ...                        0.0                       0.0   \n",
      "1  ...                        1.0                       0.0   \n",
      "2  ...                        0.0                       0.0   \n",
      "3  ...                        0.0                       0.0   \n",
      "4  ...                        1.0                       0.0   \n",
      "\n",
      "   cat__mental_iritate_False  cat__mental_iritate_nan  \\\n",
      "0                        1.0                      0.0   \n",
      "1                        1.0                      0.0   \n",
      "2                        1.0                      0.0   \n",
      "3                        1.0                      0.0   \n",
      "4                        1.0                      0.0   \n",
      "\n",
      "   cat__mental_lelah_False  cat__mental_lelah_True  cat__mental_lelah_nan  \\\n",
      "0                      0.0                     1.0                    0.0   \n",
      "1                      1.0                     0.0                    0.0   \n",
      "2                      1.0                     0.0                    0.0   \n",
      "3                      0.0                     1.0                    0.0   \n",
      "4                      0.0                     1.0                    0.0   \n",
      "\n",
      "   cat__mental_stres_False  cat__mental_stres_True  cat__mental_stres_nan  \n",
      "0                      0.0                     1.0                    0.0  \n",
      "1                      1.0                     0.0                    0.0  \n",
      "2                      0.0                     1.0                    0.0  \n",
      "3                      0.0                     1.0                    0.0  \n",
      "4                      0.0                     1.0                    0.0  \n",
      "\n",
      "[5 rows x 107 columns]\n",
      "\n",
      "================================================================================\n",
      "Statistik deskriptif data setelah preprocessing:\n",
      "================================================================================\n",
      "          num__usia  num__jumlah_anak  num__usia_anak  num__lama_bekerja  \\\n",
      "count  1.100000e+01      1.100000e+01    1.100000e+01       1.100000e+01   \n",
      "mean  -1.029480e-15     -9.083643e-17    1.009294e-17       1.009294e-16   \n",
      "std    1.048809e+00      1.048809e+00    1.048809e+00       1.048809e+00   \n",
      "min   -2.281916e+00     -9.819805e-01   -9.128709e-01      -1.955033e+00   \n",
      "25%   -5.775221e-01     -9.819805e-01   -9.128709e-01      -1.117162e-01   \n",
      "50%    1.972027e-01      2.182179e-01    9.128709e-02       1.955033e-01   \n",
      "75%    6.620375e-01      8.183171e-01    5.933661e-01       6.563324e-01   \n",
      "max    1.436762e+00      1.418416e+00    2.099603e+00       1.117162e+00   \n",
      "\n",
      "       num__waktu_bekerja_seminggu  num__beban_sks  num__mhs_bimbingan  \\\n",
      "count                 1.100000e+01    1.100000e+01        1.100000e+01   \n",
      "mean                 -3.986710e-16   -5.109549e-17       -1.513940e-17   \n",
      "std                   1.048809e+00    1.048809e+00        1.048809e+00   \n",
      "min                  -1.663602e+00   -1.323277e+00       -1.301041e+00   \n",
      "25%                  -8.386190e-01   -6.372682e-01       -7.506007e-01   \n",
      "50%                  -1.636330e-01   -1.623393e-01       -3.102483e-01   \n",
      "75%                   1.036342e+00    7.806583e-01        5.704565e-01   \n",
      "max                   1.336336e+00    2.159535e+00        2.001602e+00   \n",
      "\n",
      "       num__work_life_balance  num__gaji_sesuai  cat__jenis_kelamin_Laki-laki  \\\n",
      "count               11.000000         11.000000                     11.000000   \n",
      "mean                 0.000000          0.000000                      0.636364   \n",
      "std                  1.048809          1.048809                      0.504525   \n",
      "min                 -0.957427         -0.957427                      0.000000   \n",
      "25%                 -0.957427         -0.957427                      0.000000   \n",
      "50%                  0.000000          0.000000                      1.000000   \n",
      "75%                  0.957427          0.957427                      1.000000   \n",
      "max                  1.914854          1.914854                      1.000000   \n",
      "\n",
      "       ...  cat__mental_insomnia_True  cat__mental_insomnia_nan  \\\n",
      "count  ...                  11.000000                 11.000000   \n",
      "mean   ...                   0.272727                  0.090909   \n",
      "std    ...                   0.467099                  0.301511   \n",
      "min    ...                   0.000000                  0.000000   \n",
      "25%    ...                   0.000000                  0.000000   \n",
      "50%    ...                   0.000000                  0.000000   \n",
      "75%    ...                   0.500000                  0.000000   \n",
      "max    ...                   1.000000                  1.000000   \n",
      "\n",
      "       cat__mental_iritate_False  cat__mental_iritate_nan  \\\n",
      "count                  11.000000                11.000000   \n",
      "mean                    0.909091                 0.090909   \n",
      "std                     0.301511                 0.301511   \n",
      "min                     0.000000                 0.000000   \n",
      "25%                     1.000000                 0.000000   \n",
      "50%                     1.000000                 0.000000   \n",
      "75%                     1.000000                 0.000000   \n",
      "max                     1.000000                 1.000000   \n",
      "\n",
      "       cat__mental_lelah_False  cat__mental_lelah_True  cat__mental_lelah_nan  \\\n",
      "count                11.000000               11.000000              11.000000   \n",
      "mean                  0.454545                0.454545               0.090909   \n",
      "std                   0.522233                0.522233               0.301511   \n",
      "min                   0.000000                0.000000               0.000000   \n",
      "25%                   0.000000                0.000000               0.000000   \n",
      "50%                   0.000000                0.000000               0.000000   \n",
      "75%                   1.000000                1.000000               0.000000   \n",
      "max                   1.000000                1.000000               1.000000   \n",
      "\n",
      "       cat__mental_stres_False  cat__mental_stres_True  cat__mental_stres_nan  \n",
      "count                11.000000               11.000000              11.000000  \n",
      "mean                  0.454545                0.454545               0.090909  \n",
      "std                   0.522233                0.522233               0.301511  \n",
      "min                   0.000000                0.000000               0.000000  \n",
      "25%                   0.000000                0.000000               0.000000  \n",
      "50%                   0.000000                0.000000               0.000000  \n",
      "75%                   1.000000                1.000000               0.000000  \n",
      "max                   1.000000                1.000000               1.000000  \n",
      "\n",
      "[8 rows x 107 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cek hasil preprocessing\n",
    "# Pertama, kita perlu fit preprocessor dengan data\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Dapatkan nama fitur setelah preprocessing\n",
    "feature_names_after = preprocessor.get_feature_names_out()\n",
    "\n",
    "print(f\"Jumlah fitur sebelum preprocessing: {X.shape[1]}\")\n",
    "print(f\"Jumlah fitur setelah preprocessing: {X_preprocessed.shape[1]}\")\n",
    "print(f\"\\nBentuk data asli: {X.shape}\")\n",
    "print(f\"Bentuk data setelah preprocessing: {X_preprocessed.shape}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Nama fitur setelah preprocessing:\")\n",
    "print(f\"{'='*80}\")\n",
    "for i, name in enumerate(feature_names_after, 1):\n",
    "    print(f\"{i:3d}. {name}\")\n",
    "\n",
    "# Konversi ke DataFrame untuk melihat beberapa baris pertama\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=feature_names_after)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"5 baris pertama data setelah preprocessing:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(X_preprocessed_df.head())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Statistik deskriptif data setelah preprocessing:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(X_preprocessed_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Feature selection is an important step in building machine learning models. It helps us:\n",
    "1. **Reduce overfitting** by removing irrelevant or redundant features\n",
    "2. **Improve model performance** by focusing on the most informative features\n",
    "3. **Reduce training time** by decreasing the dimensionality of the dataset\n",
    "4. **Enhance model interpretability** by identifying the key drivers\n",
    "\n",
    "In this section, we will perform feature selection based on **correlation analysis**:\n",
    "- **Correlation with target variable**: Identifies which features have the strongest relationship with the target\n",
    "- **Multicollinearity detection**: Identifies highly correlated features that provide redundant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 44\n",
      "Feature names: ['usia', 'jenis_kelamin', 'kota_asal', 'status_pernikahan', 'jumlah_anak', 'usia_anak', 'tinggal_sendiri', 'tinggal_pasangan', 'tinggal_anak', 'tinggal_ortu', 'tinggal_mertua', 'tinggal_saudara', 'tinggal_teman', 'profesi', 'bidang', 'lama_bekerja', 'mode_bekerja', 'jarak', 'waktu_bekerja_seminggu', 'beban_sks', 'mhs_bimbingan', 'jabatan_struktural', 'jabatan_fungsional', 'sertifikasi', 'status_keaktifan', 'fisik_mata', 'fisik_punggung', 'fisik_tensi', 'fisik_lemah', 'fisik_kepala', 'fisik_obesitas', 'fisik_imun', 'fisik_carpal', 'mental_anxiety', 'mental_burnout', 'mental_depresi', 'mental_distress', 'mental_konsentrasi', 'mental_insomnia', 'mental_iritate', 'mental_lelah', 'mental_stres', 'work_life_balance', 'gaji_sesuai']\n",
      "\n",
      "Numerical features for correlation analysis: 9\n"
     ]
    }
   ],
   "source": [
    "# First, let's check the shape of our feature set\n",
    "print(f\"Original number of features: {X.shape[1]}\")\n",
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "\n",
    "# Separate numerical features for correlation analysis\n",
    "# We'll only analyze numerical features as correlation works best with numeric data\n",
    "X_numerical = X.select_dtypes(include=['int64', 'float64'])\n",
    "print(f\"\\nNumerical features for correlation analysis: {X_numerical.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correlation Matrix Visualization\n",
    "\n",
    "Let's visualize the correlation matrix to understand the relationships between features and identify potential multicollinearity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features\n",
    "correlation_matrix = X_numerical.corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Numerical Features', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation with Target Variable\n",
    "\n",
    "Now let's examine how each feature correlates with our target variable (`skor_total`). Features with higher absolute correlation values have a stronger linear relationship with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with target variable for numerical features only\n",
    "target_correlation = X_numerical.corrwith(y).sort_values(ascending=False)\n",
    "\n",
    "# Display correlation values\n",
    "print(\"Correlation with Target Variable (skor_total):\")\n",
    "print(\"=\"*60)\n",
    "for feature, corr in target_correlation.items():\n",
    "    print(f\"{feature:40s}: {corr:7.4f}\")\n",
    "\n",
    "# Visualize correlation with target\n",
    "plt.figure(figsize=(10, 8))\n",
    "target_correlation.plot(kind='barh', color='steelblue')\n",
    "plt.title('Feature Correlation with Target Variable (skor_total)', fontsize=14, pad=15)\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detecting Multicollinearity\n",
    "\n",
    "Multicollinearity occurs when two or more features are highly correlated with each other. This can cause problems in regression models because:\n",
    "- It makes it difficult to determine the individual effect of each feature\n",
    "- It can lead to unstable coefficient estimates\n",
    "- It increases the variance of coefficient estimates\n",
    "\n",
    "We'll identify pairs of features with high correlation (> 0.8 or < -0.8) and consider removing one from each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated feature pairs\n",
    "def find_high_correlation_pairs(corr_matrix, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Find pairs of features with correlation above threshold\n",
    "    \"\"\"\n",
    "    high_corr_pairs = []\n",
    "    \n",
    "    # Get the upper triangle of the correlation matrix (to avoid duplicates)\n",
    "    upper_triangle = np.triu(np.abs(corr_matrix), k=1)\n",
    "    \n",
    "    # Find pairs with high correlation\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if upper_triangle[i, j] > threshold:\n",
    "                high_corr_pairs.append({\n",
    "                    'feature_1': corr_matrix.columns[i],\n",
    "                    'feature_2': corr_matrix.columns[j],\n",
    "                    'correlation': corr_matrix.iloc[i, j]\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(high_corr_pairs)\n",
    "\n",
    "# Find highly correlated pairs (threshold = 0.8)\n",
    "high_corr_df = find_high_correlation_pairs(correlation_matrix, threshold=0.8)\n",
    "\n",
    "if len(high_corr_df) > 0:\n",
    "    print(f\"Found {len(high_corr_df)} pairs of highly correlated features (|r| > 0.8):\")\n",
    "    print(\"=\"*80)\n",
    "    print(high_corr_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No highly correlated feature pairs found (threshold = 0.8)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection Strategy\n",
    "\n",
    "Based on the correlation analysis, we'll select features using the following criteria:\n",
    "\n",
    "1. **Remove one feature from highly correlated pairs** (to reduce multicollinearity)\n",
    "   - Keep the feature with higher absolute correlation with the target\n",
    "   \n",
    "2. **Keep features with meaningful correlation with target** (optional threshold-based filtering)\n",
    "   - You can set a minimum correlation threshold if needed\n",
    "\n",
    "Let's implement this selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select features based on correlation\n",
    "def select_features_by_correlation(X, y, corr_threshold=0.8, min_target_corr=None):\n",
    "    \"\"\"\n",
    "    Select features by:\n",
    "    1. Removing one from each highly correlated pair (keeping the one with higher target correlation)\n",
    "    2. Optionally filtering by minimum correlation with target\n",
    "    \n",
    "    Parameters:\n",
    "    - X: feature dataframe\n",
    "    - y: target variable\n",
    "    - corr_threshold: threshold for detecting high correlation between features\n",
    "    - min_target_corr: minimum absolute correlation with target (None = no filtering)\n",
    "    \"\"\"\n",
    "    # Separate numerical and categorical features\n",
    "    X_num = X.select_dtypes(include=['int64', 'float64'])\n",
    "    X_cat = X.select_dtypes(include=['object', 'bool'])\n",
    "    \n",
    "    # Calculate correlations\n",
    "    feature_corr_matrix = X_num.corr()\n",
    "    target_corr = X_num.corrwith(y).abs()\n",
    "    \n",
    "    # Find features to remove due to multicollinearity\n",
    "    features_to_remove = set()\n",
    "    \n",
    "    for i in range(len(feature_corr_matrix.columns)):\n",
    "        for j in range(i+1, len(feature_corr_matrix.columns)):\n",
    "            feat_i = feature_corr_matrix.columns[i]\n",
    "            feat_j = feature_corr_matrix.columns[j]\n",
    "            \n",
    "            if abs(feature_corr_matrix.iloc[i, j]) > corr_threshold:\n",
    "                # Remove the feature with lower correlation with target\n",
    "                if target_corr[feat_i] < target_corr[feat_j]:\n",
    "                    features_to_remove.add(feat_i)\n",
    "                else:\n",
    "                    features_to_remove.add(feat_j)\n",
    "    \n",
    "    # Apply minimum target correlation filter if specified\n",
    "    if min_target_corr is not None:\n",
    "        low_corr_features = target_corr[target_corr < min_target_corr].index.tolist()\n",
    "        features_to_remove.update(low_corr_features)\n",
    "    \n",
    "    # Select features\n",
    "    selected_numerical = [f for f in X_num.columns if f not in features_to_remove]\n",
    "    \n",
    "    # Combine with categorical features\n",
    "    X_selected = pd.concat([X_num[selected_numerical], X_cat], axis=1)\n",
    "    \n",
    "    return X_selected, list(features_to_remove), selected_numerical\n",
    "\n",
    "# Apply feature selection\n",
    "# Adjust parameters as needed:\n",
    "# - corr_threshold: how correlated features must be to consider removing one (default 0.8)\n",
    "# - min_target_corr: minimum correlation with target (None = keep all, or set to e.g., 0.1)\n",
    "X_selected, removed_features, selected_num_features = select_features_by_correlation(\n",
    "    X, y, \n",
    "    corr_threshold=0.8, \n",
    "    min_target_corr=None  # Change to a value like 0.05 if you want to filter by target correlation\n",
    ")\n",
    "\n",
    "print(f\"Original number of features: {X.shape[1]}\")\n",
    "print(f\"Selected number of features: {X_selected.shape[1]}\")\n",
    "print(f\"Number of features removed: {len(removed_features)}\")\n",
    "print(f\"\\nRemoved features:\")\n",
    "for feat in removed_features:\n",
    "    print(f\"  - {feat}\")\n",
    "print(f\"\\nSelected numerical features ({len(selected_num_features)}):\")\n",
    "for feat in selected_num_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Update Features for Model Training\n",
    "\n",
    "Now we'll update our feature set `X` to use the selected features. This will be used in the subsequent model training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X with selected features\n",
    "X = X_selected.copy()\n",
    "\n",
    "print(f\"✓ Feature set updated!\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "print(f\"  Samples: {X.shape[0]}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data Into 5 Folds\n",
    "\n",
    "```python\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "```\n",
    "\n",
    "This line initializes a K-Fold cross-validator from scikit-learn's model selection module. Let's break down the parameters:\n",
    "\n",
    "- `n_splits=5`: This sets up 5-fold cross-validation. The data will be divided into 5 equal parts or \"folds\".\n",
    "- `shuffle=True`: This parameter tells the cross-validator to shuffle the data before splitting it into folds. This helps to ensure that the order of the data doesn't affect the results.\n",
    "- `random_state=2024`: This sets a specific random seed for reproducibility. Using the same random state will ensure that the data is shuffled in the same way every time the code is run.\n",
    "\n",
    "In 5-fold cross-validation:\n",
    "1. The data is divided into 5 equal subsets or folds.\n",
    "2. The model is trained on 4 folds and tested on the remaining fold.\n",
    "3. This process is repeated 5 times, with each fold serving as the test set exactly once.\n",
    "4. The performance metrics are then averaged across all 5 iterations.\n",
    "\n",
    "This method helps to get a more robust estimate of the model's performance by using all the data for both training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "\n",
    "In this experiment, I tried to simultaneously use five models: LinearRegression, XGBoost, RandomForest, GradientBoosting, and Support Vector Machine. The model that performs best will be used to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LR': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'XGB': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=2024))]),\n",
    "    'RFR': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', RandomForestRegressor(n_estimators=100, random_state=2024))]),\n",
    "    'GBR': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', GradientBoostingRegressor(n_estimators=100, random_state=2024))]),\n",
    "    'SVR': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', SVR(kernel='rbf', C=1.0, epsilon=0.1))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {model: {'r2': [], 'rmse': [], 'mae': []} for model in models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "In this part of the code, we are training the machine learning model using the training data. The model learns the relationship between the input features and the target variable by adjusting its internal parameters based on the training data. The goal is to minimize the error between the predicted values and the actual values in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        results[name]['r2'].append(r2_score(y_test, y_pred))\n",
    "        results[name]['rmse'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        results[name]['mae'].append(np.mean(np.abs(y_test - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model\n",
    "\n",
    "We use three metrics to evaluate the performance of the model:\n",
    "* R2 Score: It is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. The R2 score ranges from 0 to 1, where 1 indicates a perfect fit and 0 indicates no relationship between the independent and dependent variables.\n",
    "* RMSE (Root Mean Squared Error): It is a measure of the differences between values predicted by a model and the values observed. It is the square root of the average of the squared differences between the predicted and actual values.\n",
    "* MAE (Mean Absolute Error): It is a measure of errors between paired observations expressing the same phenomenon. It is the average of the absolute differences between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Average R-squared: {np.mean(metrics['r2']):.4f} (+/- {np.std(metrics['r2']):.4f})\")\n",
    "    print(f\"Average RMSE: {np.mean(metrics['rmse']):.4f} (+/- {np.std(metrics['rmse']):.4f})\")\n",
    "    print(f\"Average MAE: {np.mean(metrics['mae']):.4f} (+/- {np.std(metrics['mae']):.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the evaluation metrics, we can determine how well the model is performing and make adjustments as needed to improve its performance. From the five models, ..... performed the best, with the highest R2 score and lowest RMSE and MAE values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Feature Importance\n",
    "\n",
    "We want to check, from all of the features, which features are the most important in predicting the target variable. This can help us understand which features have the most impact on the target variable and how they contribute to the model's predictions.\n",
    "\n",
    "If the coefficients of the features are positive, it means that the feature has a positive impact on the target variable. If the coefficients are negative, it means that the feature has a negative impact (inverse) on the target variable.\n",
    "\n",
    "We will sort the features based on their coefficients to identify the most important features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name, X, y):\n",
    "    feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    if model_name == 'LR':\n",
    "        importances = model.named_steps['regressor'].coef_\n",
    "    elif model_name in ['XGB', 'RFR', 'GBR']:\n",
    "        importances = model.named_steps['regressor'].feature_importances_\n",
    "    elif model_name == 'SVR':\n",
    "        perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=2024)\n",
    "        importances = perm_importance.importances_mean\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    feature_importance = dict(zip(feature_names, importances))\n",
    "    return dict(sorted(feature_importance.items(), key=lambda item: abs(item[1]), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Feature Importance\n",
    "\n",
    "Understanding which features contribute most to a machine learning model’s predictions is crucial for interpretability and model refinement. In this section, we visualize **feature importance** for each model to see which variables have the greatest influence on the output (`skor_total`).\n",
    "\n",
    "The following function, `plot_feature_importance`, retrieves, filters, and visualizes feature importances using a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, model_name, X, y, threshold=0.01):\n",
    "    importance = get_feature_importance(model, model_name, X, y)\n",
    "    if importance is None:\n",
    "        print(f\"No feature importance available for {model_name}\")\n",
    "        return\n",
    "    \n",
    "    # Ubah ke DataFrame\n",
    "    df_imp = pd.DataFrame(list(importance.items()), columns=['Feature', 'Importance'])\n",
    "    \n",
    "    # Filter fitur dengan nilai mendekati 0 (misal ambil yang absolut > threshold)\n",
    "    df_imp = df_imp[df_imp['Importance'].abs() > threshold]\n",
    "\n",
    "    if df_imp.empty:\n",
    "        print(f\"Semua feature importance di bawah threshold ({threshold}) untuk {model_name}\")\n",
    "        return\n",
    "\n",
    "    # Urutkan dan plot\n",
    "    df_imp = df_imp.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(8, max(4, len(df_imp) * 0.4)))\n",
    "    sns.barplot(data=df_imp, x='Importance', y='Feature', palette='viridis')\n",
    "    plt.title(f'Feature Importance ({model_name})')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Contoh Pemanggilan ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nFeature Importance Plot for {name}:\")\n",
    "    plot_feature_importance(model, name, X, y, threshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Importance Value as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name, X, y):\n",
    "    feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    if model_name == 'LR':\n",
    "        importances = model.named_steps['regressor'].coef_\n",
    "    elif model_name in ['XGB', 'RFR', 'GBR']:\n",
    "        importances = model.named_steps['regressor'].feature_importances_\n",
    "    elif model_name == 'SVR':\n",
    "        # For SVR, we use permutation importance\n",
    "        perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=2024)\n",
    "        importances = perm_importance.importances_mean\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return dict(zip(feature_names, importances))\n",
    "\n",
    "# Calculate feature importances for all models\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "feature_importances = {}\n",
    "for name, model in models.items():\n",
    "    feature_importances[name] = get_feature_importance(model, name, X, y)\n",
    "\n",
    "# Create a DataFrame from the feature importances\n",
    "df_importance = pd.DataFrame(feature_importances)\n",
    "\n",
    "# Sort the DataFrame by the average importance across all models\n",
    "df_importance['avg_importance'] = df_importance.mean(axis=1)\n",
    "df_importance = df_importance.sort_values('avg_importance', ascending=False)\n",
    "df_importance = df_importance.drop('avg_importance', axis=1)\n",
    "\n",
    "# Rename the index to include the categorical labels\n",
    "new_index = []\n",
    "for feature in df_importance.index:\n",
    "    if feature.startswith('cat__'):\n",
    "        parts = feature.split('__')\n",
    "        if len(parts) == 3:\n",
    "            new_index.append(f\"{parts[1]}_{parts[2]}\")\n",
    "        else:\n",
    "            new_index.append(feature)\n",
    "    else:\n",
    "        new_index.append(feature)\n",
    "df_importance.index = new_index\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_importance.to_csv('feature_importance_comparison.csv')\n",
    "\n",
    "print(\"Feature importance comparison has been saved to 'feature_importance_comparison.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Supreme",
   "language": "python",
   "name": "supreme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
